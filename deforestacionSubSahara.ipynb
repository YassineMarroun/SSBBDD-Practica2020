{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de Sistemas de Bases de Datos - Deforestación SubSahara\n",
    "\n",
    "Partiendo del dataset facilitado por el Equipo Docente, a continuación se desarrollan las órdenes que podemos ir implementando tanto en un Terminal de línea de comandos, como en Hive, para ir resolviendo las cuestiones que se plantean en el enunciado de la Práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, creamos una carpeta en Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir deforestacionSubSahara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, incluimos en esta carpeta el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put /home/cloudera/deforestacionSubSahara/deforestationSubSahara.csv deforestacionSubSahara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 cloudera cloudera     546970 2019-11-22 06:34 deforestacionSubSahara/deforestationSubSahara.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls deforestacionSubSahara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la tabla en el Hive Editor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la elección de tablas internas o externas.\n",
    "Las tablas internas eliminan los datos que se utilizan de su ubicación original y los almacenan en una carpeta en el sistema de archivos de Hadoop contralada por Hive; mientras que las externas mantienen los datos en su ubicación original permitiendo que los datos estén disponibles para posibles cambios u otras herramientas de Hadoop.\n",
    "Partiendo de esa base, he optado por utilizar tablas externas ya que, vamos a necesitar acceder al archivo de datos para crear tablas y vistas, y después para ejecutar la función Map que se pide en el punto 5 del enunciado de la Práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deforestacionSubSahara.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile deforestacionSubSahara.hql\n",
    "\n",
    "create external table deforestacionTabla (\n",
    "  WorldBankRegion STRING, Country STRING, ISO3 STRING, wdpaID INT, ParkName STRING, Year INT, OutsideDeforestation DOUBLE, InsideDeforestation DOUBLE) \n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/cloudera/deforestacionSubSahara';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "a (jdbc:hive2://localhost:10000/default> create external table deforestacionTabl \n",
      "LE, InsideDeforestation DOUBLE) Name STRING, Year INT, OutsideDNG, Country STRIN eforestation DOUB \n",
      "BY ',' LOCATION '/user/cloudera/deforestacionSubSahara';MITED FIELDS TERMINATED  \n",
      "INFO  : Compiling command(queryId=hive_20191122063535_f7fba88d-7c2c-4cc2-800c-9170d972a980): create external table deforestacionTabla (\n",
      "WorldBankRegion STRING, Country STRING, ISO3 STRING, wdpaID INT, ParkName STRING, Year INT, OutsideDeforestation DOUBLE, InsideDeforestation DOUBLE)\n",
      "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/cloudera/deforestacionSubSahara'\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063535_f7fba88d-7c2c-4cc2-800c-9170d972a980); Time taken: 0.061 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063535_f7fba88d-7c2c-4cc2-800c-9170d972a980): create external table deforestacionTabla (\n",
      "WorldBankRegion STRING, Country STRING, ISO3 STRING, wdpaID INT, ParkName STRING, Year INT, OutsideDeforestation DOUBLE, InsideDeforestation DOUBLE)\n",
      "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/cloudera/deforestacionSubSahara'\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191122063535_f7fba88d-7c2c-4cc2-800c-9170d972a980); Time taken: 0.034 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.141 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -f deforestacionSubSahara.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar si se ha creado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191122063535_3904f5b8-1467-4b0f-a402-8093a57ae7a8): use default\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063535_3904f5b8-1467-4b0f-a402-8093a57ae7a8); Time taken: 0.061 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063535_3904f5b8-1467-4b0f-a402-8093a57ae7a8): use default\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191122063535_3904f5b8-1467-4b0f-a402-8093a57ae7a8); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.127 seconds)\n",
      "INFO  : Compiling command(queryId=hive_20191122063535_18bd8de2-55f9-4ce8-b9f3-a31993d93524): show tables\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063535_18bd8de2-55f9-4ce8-b9f3-a31993d93524); Time taken: 0.002 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063535_18bd8de2-55f9-4ce8-b9f3-a31993d93524): show tables\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191122063535_18bd8de2-55f9-4ce8-b9f3-a31993d93524); Time taken: 0.009 seconds\n",
      "INFO  : OK\n",
      "+---------------------+--+\n",
      "|      tab_name       |\n",
      "+---------------------+--+\n",
      "| deforestaciontabla  |\n",
      "+---------------------+--+\n",
      "1 row selected (0.062 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \"use default; show tables;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos crear la vista que se pide en el punto 3 del enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191122063737_b5d9a793-1a75-4b95-bd31-5159a0d297ef): create view deforestacionVista as select ISO3, ParkName, wdpaID, AVG(OutsideDeforestation) as MediaOutsideDeforestation, AVG(InsideDeforestation) as MediaInsideDeforestation from deforestacionTabla GROUP BY ISO3, ParkName, wdpaID\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:iso3, type:string, comment:null), FieldSchema(name:parkname, type:string, comment:null), FieldSchema(name:wdpaid, type:int, comment:null), FieldSchema(name:mediaoutsidedeforestation, type:double, comment:null), FieldSchema(name:mediainsidedeforestation, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063737_b5d9a793-1a75-4b95-bd31-5159a0d297ef); Time taken: 0.104 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063737_b5d9a793-1a75-4b95-bd31-5159a0d297ef): create view deforestacionVista as select ISO3, ParkName, wdpaID, AVG(OutsideDeforestation) as MediaOutsideDeforestation, AVG(InsideDeforestation) as MediaInsideDeforestation from deforestacionTabla GROUP BY ISO3, ParkName, wdpaID\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191122063737_b5d9a793-1a75-4b95-bd31-5159a0d297ef); Time taken: 0.022 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.178 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \\\n",
    "\"create view deforestacionVista as select ISO3, ParkName, wdpaID, AVG(OutsideDeforestation) as MediaOutsideDeforestation, AVG(InsideDeforestation) as MediaInsideDeforestation from deforestacionTabla GROUP BY ISO3, ParkName, wdpaID;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la tabla creada, los datos ya incluidos en ella y habiendo creado la vista, ya es posible realizar las tres consultas que pide el punto 4 del enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primera consulta. ¿Cuál es el porcentaje de deforestación interno del parque Rusizi en 2011?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191122063838_3f5a2ff5-239f-45f4-969c-eed19c98ddd3): select ParkName, InsideDeforestation from deforestacionTabla where ParkName = 'Rusizi' and Year = 2011\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:parkname, type:string, comment:null), FieldSchema(name:insidedeforestation, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063838_3f5a2ff5-239f-45f4-969c-eed19c98ddd3); Time taken: 0.108 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063838_3f5a2ff5-239f-45f4-969c-eed19c98ddd3): select ParkName, InsideDeforestation from deforestacionTabla where ParkName = 'Rusizi' and Year = 2011\n",
      "INFO  : Completed executing command(queryId=hive_20191122063838_3f5a2ff5-239f-45f4-969c-eed19c98ddd3); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "+-----------+----------------------+--+\n",
      "| parkname  | insidedeforestation  |\n",
      "+-----------+----------------------+--+\n",
      "| Rusizi    | 27.43                |\n",
      "+-----------+----------------------+--+\n",
      "1 row selected (0.236 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \\\n",
    "\"select ParkName, InsideDeforestation from deforestacionTabla where ParkName = 'Rusizi' and Year = 2011;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda consulta.\n",
    "¿Cuáles son los 10 parques que tienen mayor porcentaje medio de deforestación interno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191122063838_b4a33a9d-ce43-46b7-a0c5-75c39e9715e2): select ParkName, CAST(MediaInsideDeforestation as DECIMAL(10,2)) as MediaInsideDeforestation from deforestacionVista ORDER BY MediaInsideDeforestation DESC limit 10\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:parkname, type:string, comment:null), FieldSchema(name:mediainsidedeforestation, type:decimal(10,2), comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063838_b4a33a9d-ce43-46b7-a0c5-75c39e9715e2); Time taken: 0.143 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063838_b4a33a9d-ce43-46b7-a0c5-75c39e9715e2): select ParkName, CAST(MediaInsideDeforestation as DECIMAL(10,2)) as MediaInsideDeforestation from deforestacionVista ORDER BY MediaInsideDeforestation DESC limit 10\n",
      "INFO  : Query ID = hive_20191122063838_b4a33a9d-ce43-46b7-a0c5-75c39e9715e2\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1574406835787_0037, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1574406835787_0037/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1574406835787_0037\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-11-22 06:38:31,507 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-11-22 06:38:37,756 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec\n",
      "INFO  : 2019-11-22 06:38:46,115 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.39 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 390 msec\n",
      "INFO  : Ended Job = job_1574406835787_0037\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1574406835787_0038, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1574406835787_0038/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1574406835787_0038\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-11-22 06:38:53,856 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-11-22 06:39:00,103 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.28 sec\n",
      "INFO  : 2019-11-22 06:39:07,414 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.07 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 70 msec\n",
      "INFO  : Ended Job = job_1574406835787_0038\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.39 sec   HDFS Read: 556019 HDFS Write: 23313 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.07 sec   HDFS Read: 28441 HDFS Write: 161 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 7 seconds 460 msec\n",
      "INFO  : Completed executing command(queryId=hive_20191122063838_b4a33a9d-ce43-46b7-a0c5-75c39e9715e2); Time taken: 43.82 seconds\n",
      "INFO  : OK\n",
      "+--------------------+---------------------------+--+\n",
      "|      parkname      | mediainsidedeforestation  |\n",
      "+--------------------+---------------------------+--+\n",
      "| Ora-Iuleha-Ozalla  | 92.69                     |\n",
      "| Okeluse            | 88.77                     |\n",
      "| Eastern Mau        | 85.76                     |\n",
      "| Mafuga             | 85.23                     |\n",
      "| Sao Hill           | 85.08                     |\n",
      "| Okavu - Reru       | 82.81                     |\n",
      "| Desiri             | 81.63                     |\n",
      "| Gulosilo           | 80.52                     |\n",
      "| Ekiadolor          | 80.23                     |\n",
      "| Ogbesse            | 79.04                     |\n",
      "+--------------------+---------------------------+--+\n",
      "10 rows selected (44.038 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \\\n",
    "\"select ParkName, CAST(MediaInsideDeforestation as DECIMAL(10,2)) as MediaInsideDeforestation from deforestacionVista ORDER BY MediaInsideDeforestation DESC limit 10;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tercera consulta.\n",
    "¿Cuáles son los 10 países cuyos parques tienen el mayor porcentaje de deforestación interno en 2012?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 1ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191122063939_99284eaa-5af4-41e7-9190-351238a68885): select Country, CAST(SUM(InsideDeforestation) as DECIMAL(10,2)) as MayorInsideDeforestation from deforestacionTabla where Year = 2012 GROUP BY Country ORDER BY MayorInsideDeforestation DESC limit 10\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:country, type:string, comment:null), FieldSchema(name:mayorinsidedeforestation, type:decimal(10,2), comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191122063939_99284eaa-5af4-41e7-9190-351238a68885); Time taken: 0.104 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191122063939_99284eaa-5af4-41e7-9190-351238a68885): select Country, CAST(SUM(InsideDeforestation) as DECIMAL(10,2)) as MayorInsideDeforestation from deforestacionTabla where Year = 2012 GROUP BY Country ORDER BY MayorInsideDeforestation DESC limit 10\n",
      "INFO  : Query ID = hive_20191122063939_99284eaa-5af4-41e7-9190-351238a68885\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1574406835787_0039, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1574406835787_0039/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1574406835787_0039\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-11-22 06:39:34,649 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-11-22 06:39:40,934 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec\n",
      "INFO  : 2019-11-22 06:39:48,271 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.92 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 920 msec\n",
      "INFO  : Ended Job = job_1574406835787_0039\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1574406835787_0040, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1574406835787_0040/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1574406835787_0040\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-11-22 06:39:56,859 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-11-22 06:40:02,065 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.04 sec\n",
      "INFO  : 2019-11-22 06:40:09,374 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.8 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 800 msec\n",
      "INFO  : Ended Job = job_1574406835787_0040\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.92 sec   HDFS Read: 555191 HDFS Write: 671 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.8 sec   HDFS Read: 5797 HDFS Write: 172 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 6 seconds 720 msec\n",
      "INFO  : Completed executing command(queryId=hive_20191122063939_99284eaa-5af4-41e7-9190-351238a68885); Time taken: 42.497 seconds\n",
      "INFO  : OK\n",
      "+---------------------------+---------------------------+--+\n",
      "|          country          | mayorinsidedeforestation  |\n",
      "+---------------------------+---------------------------+--+\n",
      "| Nigeria                   | 2721.6                    |\n",
      "| Ghana                     | 2269.75                   |\n",
      "| Kenya                     | 1241.21                   |\n",
      "| Uganda                    | 843.69                    |\n",
      "| Tanzania                  | 692.81                    |\n",
      "| Madagascar                | 381.52                    |\n",
      "| Guinea                    | 262.46                    |\n",
      "| Cameroon                  | 212.84                    |\n",
      "| Central African Republic  | 147.87                    |\n",
      "| Sierra Leone              | 83.61                     |\n",
      "+---------------------------+---------------------------+--+\n",
      "10 rows selected (42.669 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \\\n",
    "\"select Country, CAST(SUM(InsideDeforestation) as DECIMAL(10,2)) as MayorInsideDeforestation from deforestacionTabla where Year = 2012 GROUP BY Country ORDER BY MayorInsideDeforestation DESC limit 10;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a desarrollar la función map para la primera consulta, tal como pide el punto 5 del enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos y ejecutamos la función map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    " \n",
    "import sys\n",
    " \n",
    "for line in sys.stdin:\n",
    "\tdata = line.strip().split(\",\")\n",
    "\tif len(data) == 8:\n",
    "\t\tWorldBankRegion, Country, ISO3, wdpaID, ParkName, Year, OutsideDeforestation, InsideDeforestation = data\n",
    "\t\tif ParkName == \"Rusizi\" and Year == \"2011\":\n",
    "\t\t\tprint (\"%s %s\" % (ParkName, InsideDeforestation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder manejar el archivo mapper.py es necesario habilitar los permisos de acceso para lectura y escritura, y permitir que el archivo sea ejecutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rusizi 27.43\r\n"
     ]
    }
   ],
   "source": [
    "! cat /home/cloudera/deforestacionSubSahara/deforestationSubSahara.csv | ./mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya por último, probamos a ejecutar el código de la función Map en Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/11/22 06:41:27 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [mapper.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob6449263844419356830.jar tmpDir=null\n",
      "19/11/22 06:41:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/11/22 06:41:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/11/22 06:41:29 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "19/11/22 06:41:29 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "19/11/22 06:41:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1574406835787_0041\n",
      "19/11/22 06:41:30 INFO impl.YarnClientImpl: Submitted application application_1574406835787_0041\n",
      "19/11/22 06:41:30 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1574406835787_0041/\n",
      "19/11/22 06:41:30 INFO mapreduce.Job: Running job: job_1574406835787_0041\n",
      "19/11/22 06:41:37 INFO mapreduce.Job: Job job_1574406835787_0041 running in uber mode : false\n",
      "19/11/22 06:41:37 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "19/11/22 06:41:42 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "19/11/22 06:41:43 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/11/22 06:41:48 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/11/22 06:41:48 INFO mapreduce.Job: Job job_1574406835787_0041 completed successfully\n",
      "19/11/22 06:41:48 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=22\n",
      "\t\tFILE: Number of bytes written=382885\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=551360\n",
      "\t\tHDFS: Number of bytes written=14\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=7884\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3478\n",
      "\t\tTotal time spent by all map tasks (ms)=7884\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3478\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7884\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3478\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8073216\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3561472\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8520\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=14\n",
      "\t\tMap output materialized bytes=28\n",
      "\t\tInput split bytes=294\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=28\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=95\n",
      "\t\tCPU time spent (ms)=2510\n",
      "\t\tPhysical memory (bytes) snapshot=755425280\n",
      "\t\tVirtual memory (bytes) snapshot=4728496128\n",
      "\t\tTotal committed heap usage (bytes)=748158976\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=551066\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=14\n",
      "19/11/22 06:41:48 INFO streaming.StreamJob: Output directory: /user/cloudera/deforestacionSubSahara/salidaConsulta1\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file mapper.py -mapper mapper.py -input /user/cloudera/deforestacionSubSahara/deforestationSubSahara.csv -output /user/cloudera/deforestacionSubSahara/salidaConsulta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 cloudera cloudera     546970 2019-11-22 06:34 deforestacionSubSahara/deforestationSubSahara.csv\n",
      "drwxr-xr-x   - cloudera cloudera          0 2019-11-22 06:41 deforestacionSubSahara/salidaConsulta1\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls deforestacionSubSahara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 cloudera cloudera          0 2019-11-22 06:41 deforestacionSubSahara/salidaConsulta1/_SUCCESS\r\n",
      "-rw-r--r--   1 cloudera cloudera         14 2019-11-22 06:41 deforestacionSubSahara/salidaConsulta1/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls deforestacionSubSahara/salidaConsulta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rusizi 27.43\t\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -cat deforestacionSubSahara/salidaConsulta1/part-00000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
